# Testing Guide - Realtime API Integration

## âœ… What Was Fixed

1. **OpenAI Realtime API Format** - Updated to use correct JSON payload format
2. **Manual Voice Button** - Added toggle button for voice conversation (not always-on)
3. **Hybrid Mode** - Text input works with regular Chat API, voice uses Realtime API

## ğŸš€ Quick Test

### Test 1: Text Input (No Voice)

1. Open: http://localhost:8080/unified-realtime.html
2. Type in text box: "×™×© ×œ×›× × ×•×¨×•×¤×Ÿ?"
3. Click "×©×œ×—"
4. âœ… Should see response from Chat API

### Test 2: Voice Conversation

1. Open: http://localhost:8080/unified-realtime.html
2. Click microphone button ğŸ¤
3. Grant microphone permission
4. Wait for "âœ… ×©×™×—×” ×§×•×œ×™×ª ××—×•×‘×¨×ª!"
5. Speak: "×™×© ×œ×›× × ×•×¨×•×¤×Ÿ?"
6. âœ… Should hear natural AI response

### Test 3: Stop Voice

1. While voice is active (red microphone)
2. Click microphone button again
3. âœ… Should stop voice and show "ğŸ”´ ×©×™×—×” ×§×•×œ×™×ª ×”×•×¤×¡×§×”"

### Test 4: Switch Modes

1. Start with text input - ask a question
2. Click microphone - start voice
3. Ask voice question
4. Click microphone - stop voice
5. Use text input again
6. âœ… Both should work independently

## âš ï¸ Important Note About Realtime API

The OpenAI Realtime API is currently in **beta** and has specific requirements:

### API Access
- Requires **Realtime API access** on your OpenAI account
- May need to join waitlist: https://openai.com/waitlist/realtime-api
- Check your API dashboard: https://platform.openai.com/settings

### If You Don't Have Realtime API Access Yet:

**Option 1: Use Text Only**
- The text input will work fine with regular Chat API
- Just don't click the voice button

**Option 2: Use Original Version**
- Go to: http://localhost:8080/unified.html
- Uses browser TTS/STT (no API access needed)
- All features work

## ğŸ” Troubleshooting

### Error: "Session creation failed"

**Check Terminal Output:**

```bash
# Look for this error:
[Realtime Service] Error: OpenAI API error: 404
```

**Solution:**
- Your API key doesn't have Realtime API access yet
- Use text input only, or use original version

### Error: "Failed to start voice"

**Possible Causes:**
1. No microphone permission
2. API access issue
3. Network problem

**Solution:**
1. Check browser permissions
2. Check terminal logs
3. Try text input to verify server works

### Voice Button Does Nothing

**Check:**
1. Browser console (F12) for errors
2. Terminal for backend errors
3. Make sure server is running

## ğŸ“‹ What Works Now

### âœ… Working Features

1. **Text Input** - Always works (uses Chat API)
2. **Voice Button** - Manual start/stop
3. **Hybrid Mode** - Switch between text and voice
4. **Developer Mode** - Shows function calls
5. **Function Calling** - All pharmacy tools work
6. **Hebrew Support** - Both text and voice

### ğŸ¯ User Flow

```
User opens page
    â†“
Can type text immediately âœ…
    OR
Click ğŸ¤ to start voice
    â†“
Grant microphone permission
    â†“
Speak naturally
    â†“
Click ğŸ¤ to stop voice
    â†“
Can type text again
```

## ğŸ¨ UI States

### Microphone Button States

1. **Ready (Blue)** ğŸ¤
   - Click to start voice
   - Text: "×œ×—×¥ ×œ×”×ª×—×œ×ª ×©×™×—×” ×§×•×œ×™×ª"

2. **Connecting (Spinning)** â³
   - Connecting to Realtime API
   - Status: "××ª×—×‘×¨..."

3. **Active (Green)** ğŸ”´
   - Voice conversation active
   - Click to stop
   - Text: "×œ×—×¥ ×œ×¢×¦×™×¨×ª ×©×™×—×” ×§×•×œ×™×ª"

## ğŸ§ª Advanced Testing

### Test Function Calling

1. Enable developer mode (âš™ï¸ button)
2. Ask: "×ª×Ÿ ×œ×™ ××™×“×¢ ×¢×œ × ×•×¨×•×¤×Ÿ 400"
3. âœ… Should see function call box with:
   - Function: `get_medication_by_name`
   - Input: `{"name": "× ×•×¨×•×¤×Ÿ", "strength_mg": 400}`
   - Output: Full medication info

### Test Multiple Functions

1. Ask: "×™×© ×ª×—×œ×™×£ ×œ××•×¤×˜×œ×’×™×Ÿ?"
2. âœ… Should see multiple function calls:
   - `get_medication_by_name` (for ××•×¤×˜×œ×’×™×Ÿ)
   - `get_alternative_medications`

### Test Audio Mute

1. Start voice conversation
2. While AI is speaking, click ğŸ”Š
3. âœ… Should mute output
4. Click again to unmute

## ğŸ“Š Expected Behavior

| Action | Text Mode | Voice Mode |
|--------|-----------|------------|
| Type message | âœ… Uses Chat API | âœ… Uses Realtime API |
| Speak | âŒ Not active | âœ… VAD detects speech |
| Response | âŒ No audio | âœ… Natural speech |
| Latency | ~2-3 seconds | ~500ms |
| Function calls | âœ… Works | âœ… Works |

## ğŸ‰ Success Indicators

If everything works, you should see:

1. âœ… Text input works immediately
2. âœ… Microphone button clickable
3. âœ… Can start/stop voice conversation
4. âœ… Real-time speech transcription
5. âœ… Natural AI voice response
6. âœ… Function calls execute
7. âœ… Developer mode shows details
8. âœ… Can switch between modes

## ğŸ”„ Comparison

### This Version (unified-realtime.html)
- Text: Regular Chat API
- Voice: Realtime API (when button clicked)
- **Hybrid approach** - best of both worlds

### Original Version (unified.html)
- Text: Regular Chat API
- Voice: Browser TTS/STT
- **Simpler** - no API access needed

## ğŸ’¡ Pro Tips

1. **Start with text** to verify server works
2. **Then try voice** if you have API access
3. **Use developer mode** to understand what's happening
4. **Check terminal logs** for debugging
5. **Compare with original version** to see differences

## ğŸ“ Next Steps

If everything works:
- âœ… You have a working hybrid implementation!
- âœ… Users can choose text or voice
- âœ… Lower latency when using voice
- âœ… Fallback to text if no Realtime API access

If voice doesn't work:
- âœ… Text still works fine
- âœ… Use original version for browser-based voice
- âœ… Request Realtime API access from OpenAI

---

**Ready to test! Try it out: http://localhost:8080/unified-realtime.html**
